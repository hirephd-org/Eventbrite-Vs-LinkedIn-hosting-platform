{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf/jEubimpnjvIrgzq8n0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bornalig/HirePhD-Data-Event/blob/main/Event%20platform%20comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "rlG6a0xdZ1z_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting the csv files into the colab, 30 numbers of files need to be uploaded through the choose file option\n",
        "\n",
        "from google.colab import files\n",
        "uploaded=files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BURvwbTWZ833",
        "outputId": "58abe159-cd98-4315-c9c1-d251c7c5d051"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-420d3faf-1b49-407f-b80e-6efd5396363c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-420d3faf-1b49-407f-b80e-6efd5396363c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 30_report.csv to 30_report.csv\n",
            "Saving 4_report.csv to 4_report.csv\n",
            "Saving 28_report.csv to 28_report.csv\n",
            "Saving 31_report.csv to 31_report.csv\n",
            "Saving 29_report.csv to 29_report.csv\n",
            "Saving 27_report.csv to 27_report.csv\n",
            "Saving 26_report.csv to 26_report.csv\n",
            "Saving 32_report.csv to 32_report.csv\n",
            "Saving 24_report.csv to 24_report.csv\n",
            "Saving 11_report.csv to 11_report.csv\n",
            "Saving 8_report.csv to 8_report.csv\n",
            "Saving 2_report.csv to 2_report.csv\n",
            "Saving 3_report.csv to 3_report.csv\n",
            "Saving 21_report.csv to 21_report.csv\n",
            "Saving 14_report.csv to 14_report.csv\n",
            "Saving 10_report.csv to 10_report.csv\n",
            "Saving 7_report.csv to 7_report.csv\n",
            "Saving 5_report.csv to 5_report.csv\n",
            "Saving 6_report.csv to 6_report.csv\n",
            "Saving 15_report.csv to 15_report.csv\n",
            "Saving 9_report.csv to 9_report.csv\n",
            "Saving 20_report.csv to 20_report.csv\n",
            "Saving 22_report.csv to 22_report.csv\n",
            "Saving 19_report.csv to 19_report.csv\n",
            "Saving 18_report.csv to 18_report.csv\n",
            "Saving 16_report.csv to 16_report.csv\n",
            "Saving 23_report.csv to 23_report.csv\n",
            "Saving 12_report.csv to 12_report.csv\n",
            "Saving 17_report.csv to 17_report.csv\n",
            "Saving 13_report.csv to 13_report.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# list all csv files only\n",
        "csv_files = glob.glob('*.{}'.format('csv'))\n",
        "csv_files\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_csv_append = pd.DataFrame()\n",
        "\n",
        "# append the CSV files\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(file)\n",
        "    df_csv_append = df_csv_append.append(df, ignore_index=True)\n",
        "\n",
        "df_csv_append"
      ],
      "metadata": {
        "id": "YQyvCjMcaQyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv_append.fillna(0)"
      ],
      "metadata": {
        "id": "n1FixDIvaUxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the data to a report csv file\n",
        "df_csv_append.to_csv(\"report.csv\", index= False)"
      ],
      "metadata": {
        "id": "h7wcSxk4ae3p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find duplicate data based on rows\n",
        "#import modules\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#reading the csv file\n",
        "report_data = pd.read_csv('report.csv')\n",
        "report_data.head()\n",
        "report_data.columns\n",
        "duplicateRowsDF = report_data[report_data.duplicated()]\n",
        "print(\"Duplicate Rows except first occurrence based on all columns are :\")\n",
        "print(duplicateRowsDF)"
      ],
      "metadata": {
        "id": "wvFdO7tmalVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list the files in the directory\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vnPgD1aarsu",
        "outputId": "5d8b4fb2-6ae0-4369-a3bd-21fd98154f1c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10_report.csv  16_report.csv  22_report.csv  29_report.csv  4_report.csv  report.csv\n",
            "11_report.csv  17_report.csv  23_report.csv  2_report.csv   5_report.csv  sample_data\n",
            "12_report.csv  18_report.csv  24_report.csv  30_report.csv  6_report.csv\n",
            "13_report.csv  19_report.csv  26_report.csv  31_report.csv  7_report.csv\n",
            "14_report.csv  20_report.csv  27_report.csv  32_report.csv  8_report.csv\n",
            "15_report.csv  21_report.csv  28_report.csv  3_report.csv   9_report.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the conent of the report file(the output file)\n",
        "! cat report.csv"
      ],
      "metadata": {
        "id": "gVQRK9w6av0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the csv file using read_csv\n",
        "# storing the data frame in variable called df\n",
        "df = pd.read_csv('report.csv')\n",
        "\n",
        "# creating a list of column names by\n",
        "# calling the .columns\n",
        "list_of_column_names = list(df.columns)\n",
        "\n",
        "# displaying the list of column names\n",
        "print('List of column names : ',\n",
        "      list_of_column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJRzi7j0a333",
        "outputId": "3bd93b34-c99f-4fe8-cc9a-9fbfd7cc6085"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of column names :  ['Order #', 'Order Date', 'First Name', 'Last Name', 'Email', 'Quantity', 'Price Tier', 'Ticket Type', 'Attendee #', 'Group', 'Order Type', 'Currency', 'Total Paid', 'Fees Paid', 'Eventbrite Fees', 'Eventbrite Payment Processing', 'Attendee Status', 'Home Address 1', 'Home Address 2', 'Home City', 'Home State', 'Home Zip', 'Home Country', 'Which of the following best describes you?', 'Do you agree to be contacted by recruiters?', 'Do you agree to receive future events and news from the event organizers?', 'Do you agree to receive news from the event partner(s)?', \"Any question you'd like to ask the speaker?\", 'Could we follow up with you through email?', 'Billing Address 1', 'Billing Address 2', 'Billing City', 'Billing State', 'Billing Zip', 'Billing Country', 'ID', 'Prefix', 'Cell Phone', 'Would you like to join HirePhD Slack peer support community?', 'Job Title', 'Company', 'Order ID', 'Event Name', 'Ticket Quantity', 'Ticket Price', 'Buyer First Name', 'Buyer Last Name', 'Buyer Email', 'Any question youâ€™d like to ask the speaker?', 'Event ID', 'Type', 'Questions', 'Suggestion', 'Mailing_list', 'Recruiter_contact', 'If you have a question prepared for the event, please type here. ', 'Name', 'Buyer Name', 'Do you agree to be contacted by recruiters? ', \"Any questions you'd like to ask the presenter? \", 'Which of the following best describes you? ', \"Any particular career path you'd like to hear more about? \", \"Any questions you'd like to ask the presenter?\", \"Any particular career path you'd like to hear more about?\", 'By signing up for the event, you agree to receive future events and news from the event organizers.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets select few columns for this exercise\n",
        "columns_to_select = ['Order #', 'Order Date', 'Quantity', 'Total Paid', 'Attendee Status', 'Attendee #', 'Currency']\n",
        "\n",
        "columns_to_select"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIPanR-hbJDm",
        "outputId": "2bba8e4b-f213-404b-e560-fdc76b7ca99a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Order #',\n",
              " 'Order Date',\n",
              " 'Quantity',\n",
              " 'Total Paid',\n",
              " 'Attendee Status',\n",
              " 'Attendee #',\n",
              " 'Currency']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV data\n",
        "df = pd.read_csv('report.csv')\n",
        "\n",
        "# Specify the columns you want to keep\n",
        "columns_to_keep = ['Order #', 'Order Date', 'Quantity', 'Total Paid', 'Attendee Status', 'Attendee #', 'Currency']\n",
        "\n",
        "# Keep only the specified columns\n",
        "df_subset = df[columns_to_keep]\n",
        "\n",
        "# Save the result to a new CSV file\n",
        "df_subset.to_csv('report_concise.csv', index=False)"
      ],
      "metadata": {
        "id": "DRxZe_4BbPOY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#View the data in the output file\n",
        "! cat report_concise.csv"
      ],
      "metadata": {
        "id": "VkHPImvmbduz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your CSV data\n",
        "df = pd.read_csv('report_concise.csv')\n",
        "\n",
        "# Count the number of entries (rows)\n",
        "num_entries = len(df)\n",
        "\n",
        "print(f\"Number of entries in the CSV file: {num_entries}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkwlJc9IbkeC",
        "outputId": "e80252cb-ef4d-4f89-9311-1ab1b1e640b6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries in the CSV file: 2533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to check the format of the dates find the error\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "# Creating a timezone-naive datetime object\n",
        "naive_datetime = datetime(2023, 1, 1, 12, 0, 0)\n",
        "\n",
        "# Creating a timezone-aware datetime object\n",
        "aware_datetime = datetime(2023, 1, 1, 12, 0, 0, tzinfo=timezone.utc)\n",
        "\n",
        "# Attempting to compare the two datetime objects\n",
        "try:\n",
        "    result = naive_datetime >= aware_datetime\n",
        "except TypeError as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZlrUUtrbryV",
        "outputId": "3f4e8ddc-e845-458b-82ff-d418fa519199"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: can't compare offset-naive and offset-aware datetimes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#changing the time stamp format to similar datetime zone and stamp through out the Order Date column\n",
        "# Load your CSV data\n",
        "df = pd.read_csv('report_concise.csv')\n",
        "\n",
        "# Name the column to change date stamp\n",
        "date_column = 'Order Date'\n",
        "\n",
        "# Convert the 'Order Date' column to a pandas datetime object, handling errors\n",
        "df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
        "\n",
        "# Check for rows with invalid datetime values (NaT - Not a Time)\n",
        "invalid_rows = df[df[date_column].isna()]\n",
        "\n",
        "# Display or handle invalid rows as needed\n",
        "if not invalid_rows.empty:\n",
        "    print(f\"Invalid datetime values in the following rows:\\n{invalid_rows}\")\n"
      ],
      "metadata": {
        "id": "llh9wei6bxYU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the result to a new CSV file (replace 'output_data.csv' with your desired file name)\n",
        "df.to_csv('output_data.csv', index=False)\n",
        "\n",
        "#finding the intial and last date in the column Order Date\n",
        "df=pd.read_csv('output_data.csv')\n",
        "\n",
        "\n",
        "#FINDING MAX AND MIN\n",
        "p=df['Order Date'].max()\n",
        "q=df['Order Date'].min()\n",
        "\n",
        "\n",
        "print(q)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGGKLx6zcS1v",
        "outputId": "c9ac7cc5-ff09-43d3-eeba-3d5230273e0e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-03-07 16:52:34-08:00\n",
            "2023-06-19 17:55:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum and minimum amounts paid\n",
        "df=pd.read_csv('output_data.csv')\n",
        "\n",
        "\n",
        "#FINDING MAX AND MIN\n",
        "p=df['Total Paid'].max()\n",
        "q=df['Total Paid'].min()\n",
        "\n",
        "\n",
        "print(q)\n",
        "print(p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzc51zRCcZN5",
        "outputId": "0c438712-51c7-46d2-b174-392c31bcfef7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total revenue collected in the events\n",
        "\n",
        "# Load your CSV data\n",
        "df = pd.read_csv('output_data.csv')\n",
        "\n",
        "# Assuming you have a column named 'Total paid'\n",
        "column_to_sum = 'Total Paid'\n",
        "\n",
        "# Calculate the sum of the specified column\n",
        "total_amount = df[column_to_sum].sum()\n",
        "\n",
        "print(f\"Total sum of '{column_to_sum}': {total_amount}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzbIoyslceA5",
        "outputId": "42e399c1-8cd3-4c13-9c7f-a6cf5c435214"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sum of 'Total Paid': 463.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the turn around before a specific date here(2022-07-09)\n",
        "# Load your CSV data\n",
        "df = pd.read_csv('output_data.csv')\n",
        "\n",
        "# Assuming you have a column named 'Order Date', replace it with your actual column name\n",
        "date_column = 'Order Date'\n",
        "\n",
        "# Specify the specific date (replace 'yyyy-mm-dd' with your desired date)\n",
        "specific_date = '2022-07-09'\n",
        "\n",
        "\n",
        "# Filter the DataFrame to include only entries before the specific date\n",
        "entries_before_date = df[df[date_column] < specific_date]\n",
        "\n",
        "# Count the number of entries before the specific date\n",
        "count_before_date = len(entries_before_date)\n",
        "\n",
        "print(f\"Number of entries before {specific_date}: {count_before_date}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRpwgf_wcmzX",
        "outputId": "a692b3d0-b268-429c-9cd9-ebab37815f7b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries before 2022-07-09: 1651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the turn around before a specific date here(2022-07-09)\n",
        "# Load your CSV data\n",
        "df = pd.read_csv('output_data.csv')\n",
        "\n",
        "# a column named 'Order Date'\n",
        "date_column = 'Order Date'\n",
        "\n",
        "# Specify the specific date (replace 'yyyy-mm-dd' with your desired date)\n",
        "specific_date = '2023-06-19'\n",
        "\n",
        "\n",
        "# Filter the DataFrame to include only entries before the specific date\n",
        "entries_before_date = df[df[date_column] < specific_date]\n",
        "\n",
        "# Count the number of entries before the specific date\n",
        "count_before_date = len(entries_before_date)\n",
        "\n",
        "print(f\"Number of entries before {specific_date}: {count_before_date}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g3-sp3scuTI",
        "outputId": "3bb83458-7982-486d-d936-778bbcc035a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries before 2023-06-19: 2531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5l2Sp5eZzly",
        "outputId": "d9e706b4-dbb8-4c22-d633-5f42fe8db012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries between 2022-07-09 and 2023-06-19: 880\n"
          ]
        }
      ],
      "source": [
        "# Specify the two specific dates\n",
        "start_date = '2022-07-09'\n",
        "end_date = '2023-06-19'\n",
        "\n",
        "# Filter the DataFrame to include only entries within the specified date range\n",
        "entries_within_range = df[(df[date_column] >= start_date) & (df[date_column] <= end_date)]\n",
        "\n",
        "# Count the number of entries within the specified date range\n",
        "count_within_range = len(entries_within_range)\n",
        "\n",
        "print(f\"Number of entries between {start_date} and {end_date}: {count_within_range}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARZolbJkdoTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_count = df['Attendee #'].nunique()\n",
        "\n",
        "# Display the unique count\n",
        "print(f\"Number of unique values in 'Attendee #': {unique_count}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5imN6GXc8fY",
        "outputId": "20894421-91f4-4260-83d6-4464dcc89de9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique values in 'Attendee #': 660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Replace 'your_file.csv' with the actual file path\n",
        "df = pd.read_csv('output_data.csv')\n",
        "\n",
        "# Assuming 'date_column' is the column with varying date-time stamps\n",
        "df['Order Date'] = pd.to_datetime(df['Order Date'], errors='coerce')\n",
        "\n",
        "# Format the date-time column as desired\n",
        "df['Order Date'] = df['Order Date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Save the updated DataFrame back to the CSV file\n",
        "df.to_csv('your_updated_file.csv', index=False)"
      ],
      "metadata": {
        "id": "ofzjx-l4injj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
